{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dhoni_kohli_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahibpreetsingh12/100daysofcode/blob/master/dhoni_kohli_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mRFcwqPdBd4r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "#!mkdir test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XkLgi8c_DZOp",
        "colab_type": "code",
        "outputId": "6f06260b-392b-4c17-91a5-63630818c998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UKzHviOil6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp -r /content/gdrive/My\\ Drive/train/ /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hotSzLMVPX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7bb0de0-739f-48e8-b9e7-6c9ffecca3f3"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "training_data = []\n",
        "IMG_SIZE = 150\n",
        "def create_training_data():\n",
        "   \n",
        "    DATADIR = \"train/\"\n",
        "\n",
        "    CATEGORIES = [ \"dhoni\",\"virat\"]\n",
        "\n",
        "    for category in CATEGORIES:  # do dhoni and virat\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to dhoni and virat\n",
        "        \n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dhoni 1=virat\n",
        "        \n",
        "\n",
        "        for img in os.listdir(path):  # iterate over each image per dhoni and virat\n",
        "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            \n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data),type(training_data[1]))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73 <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1O_IRlJ7fFDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "db40c173-3c22-4cb8-9cc4-3c494d28223f"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:10]:\n",
        "    print(sample[1])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zsq5AQiLbvMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    #print(training_data[0])\n",
        "    y.append(label)\n",
        "\n",
        "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE,3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Asw_m2_dLOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf10419e-4320-454d-c46c-61dcde09943b"
      },
      "cell_type": "code",
      "source": [
        "print(X[0].shape)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0XP91OSUbbXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "c5fbf686-c725-4509-b3f4-8dca9bc57ae3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "#X = X/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=32, epochs=15, validation_split=0.3)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 51 samples, validate on 22 samples\n",
            "Epoch 1/15\n",
            "51/51 [==============================] - 1s 16ms/sample - loss: 3.8804 - acc: 0.4314 - val_loss: 1.2714 - val_acc: 0.5909\n",
            "Epoch 2/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 1.4195 - acc: 0.5294 - val_loss: 1.2359 - val_acc: 0.4091\n",
            "Epoch 3/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.8279 - acc: 0.5294 - val_loss: 0.6599 - val_acc: 0.6364\n",
            "Epoch 4/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.6763 - acc: 0.4902 - val_loss: 0.7047 - val_acc: 0.4091\n",
            "Epoch 5/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.6272 - acc: 0.6275 - val_loss: 0.6729 - val_acc: 0.6364\n",
            "Epoch 6/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.5743 - acc: 0.8824 - val_loss: 0.7265 - val_acc: 0.3182\n",
            "Epoch 7/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.5095 - acc: 0.6667 - val_loss: 0.6209 - val_acc: 0.6364\n",
            "Epoch 8/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.4183 - acc: 0.9020 - val_loss: 0.6179 - val_acc: 0.6364\n",
            "Epoch 9/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.3420 - acc: 0.9608 - val_loss: 0.6221 - val_acc: 0.6364\n",
            "Epoch 10/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.2633 - acc: 0.9412 - val_loss: 0.6693 - val_acc: 0.6818\n",
            "Epoch 11/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.2773 - acc: 0.9020 - val_loss: 0.7396 - val_acc: 0.5909\n",
            "Epoch 12/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.2126 - acc: 0.9020 - val_loss: 0.7401 - val_acc: 0.5909\n",
            "Epoch 13/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.1505 - acc: 0.9412 - val_loss: 0.8389 - val_acc: 0.6364\n",
            "Epoch 14/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.1551 - acc: 0.9608 - val_loss: 0.7738 - val_acc: 0.6818\n",
            "Epoch 15/15\n",
            "51/51 [==============================] - 0s 5ms/sample - loss: 0.0844 - acc: 1.0000 - val_loss: 0.7999 - val_acc: 0.5909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcbcc8a2668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "dLzzWSf8cFYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "2cec6f18-9969-44ff-91a9-def62239e91b"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 148, 148, 128)     3584      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 148, 148, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 49, 49, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 47, 47, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 47, 47, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 64)                3686464   \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,985,281\n",
            "Trainable params: 3,985,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bE7xvPQ-cJEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('cricketer.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uC07xjULcRxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "CATEGORIES = [\"dhoni\", \"virat\"]  # will use this to convert prediction num to string value\n",
        "\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 150  # 150 in txt-based\n",
        "    img_array = cv2.imread(filepath)  # read in the image, convert to grayscale\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)  # return the image with shaping that TF wants."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeqScwMNlYRW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"cricketer.model\")\n",
        "prediction = model.predict([prepare('e3.jpeg')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ush0Kob7lvEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c46fa3eb-11f0-4d23-e425-ed66cfccce19"
      },
      "cell_type": "code",
      "source": [
        "print(CATEGORIES[int(prediction[0][0])])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dhoni\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FN2ZtY6Cmodq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}