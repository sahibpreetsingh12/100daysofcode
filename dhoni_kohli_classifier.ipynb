{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dhoni_kohli_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahibpreetsingh12/100daysofcode/blob/master/dhoni_kohli_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mRFcwqPdBd4r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "!mkdir test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XkLgi8c_DZOp",
        "colab_type": "code",
        "outputId": "de9efa74-c8c5-404a-fab3-eb0868cc4f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DOX29fW8S8Nk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp -r /content/gdrive/My\\ Drive/train /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ie2-JH5SF3OA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "virat = glob('train/virat/*.jpeg')\n",
        "dhoni = glob('train/dhoni/*.jpeg')\n",
        "\n",
        "virat_train, virat_test = train_test_split(virat, test_size=0.30)\n",
        "dhoni_train, dhoni_test = train_test_split(dhoni, test_size=0.30)\n",
        "\n",
        "TRAIN_DIR = 'train'\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "!mkdir test\n",
        "\n",
        "!mkdir test/dhoni\n",
        "files = ' '.join(dhoni_test)\n",
        "!mv -t test/dhoni $files\n",
        "\n",
        "!mkdir test/virat\n",
        "\n",
        "files = ' '.join(virat_test)\n",
        "!mv -t test/virat $files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "teAYOX3vbpk5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense,GlobalAveragePooling2D,Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRiijBqocSuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes=2\n",
        "model=InceptionV3(weights='imagenet',include_top=False)\n",
        "#to confirm we have got weights file see a file with .h5 extension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJtlqs5McmdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dd58e27-d7c4-4113-e3af-47b66b385dfb"
      },
      "cell_type": "code",
      "source": [
        "x = model.output#it is a tensor\n",
        "print(x)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"mixed10_2/concat:0\", shape=(?, ?, ?, 2048), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rFIj9_WEc4S6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x = GlobalAveragePooling2D(name='avgpool')(x)\n",
        "#print(type(x),x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(classes, activation='softmax')(x)\n",
        "#print(\"sahib\")\n",
        "#print(predictions,type(predictions))\n",
        "model = Model(inputs=model.input, outputs=predictions)\n",
        "   \n",
        "# transfer learning\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "      \n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pmzBQhhwjPEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Image Augmentation**\n",
        "\n",
        "Keras provides the ImageDataGenerator class that defines the configuration for image data preparation and augmentation. This includes capabilities such as:\n",
        "\n",
        "Sample-wise standardization.\n",
        "Feature-wise standardization.\n",
        "ZCA whitening.\n",
        "Random rotation, shifts, shear and flips.\n",
        "Dimension reordering.\n",
        "Save augmented images to disk."
      ]
    },
    {
      "metadata": {
        "id": "lkViPrPCjOOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edfa1b15-1606-4648-b725-c921d93a0f33"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "WIDTH = 299\n",
        "HEIGHT = 299\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# data prep\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,#TRAIN DIR is train\n",
        "    target_size=(HEIGHT, WIDTH),\n",
        "\t\tbatch_size=BATCH_SIZE,\n",
        "\t\tclass_mode='categorical')\n",
        "    \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    TEST_DIR,#TEST DIR is test\n",
        "    target_size=(HEIGHT, WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical')\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19 images belonging to 2 classes.\n",
            "Found 8 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2r0jpYnQjc0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6a0b9e4f-0015-44f4-9cf4-81019fa428d2"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 4\n",
        "STEPS_PER_EPOCH = 4\n",
        "VALIDATION_STEPS = 4\n",
        "\n",
        "MODEL_FILE = 'cricketer.model'\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VALIDATION_STEPS)\n",
        "  \n",
        "model.save(MODEL_FILE)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 41s 10s/step - loss: 0.7037 - acc: 0.6184 - val_loss: 0.5790 - val_acc: 0.6875\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 30s 7s/step - loss: 0.7937 - acc: 0.4737 - val_loss: 0.6218 - val_acc: 0.6562\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 31s 8s/step - loss: 0.7936 - acc: 0.5132 - val_loss: 0.5405 - val_acc: 0.7812\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 30s 8s/step - loss: 0.7340 - acc: 0.5789 - val_loss: 0.7147 - val_acc: 0.5312\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 31s 8s/step - loss: 0.7478 - acc: 0.5263 - val_loss: 0.6481 - val_acc: 0.5938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fAvJXQGhkwPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZCH58PMkzFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4daaae69-77af-49a4-c393-c1b6262070e9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(model, img):\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    print(preds)\n",
        "    return preds[0]\n",
        "\n",
        "img = image.load_img('vk14.jpeg', target_size=(HEIGHT, WIDTH))\n",
        "preds1 = predict(load_model(MODEL_FILE), img)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5764661  0.42353392]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yhVbYPZylfoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8f270b3b-e92d-4300-da35-7650f80dc5e2"
      },
      "cell_type": "code",
      "source": [
        "generator= train_datagen.flow_from_directory(\"train\", batch_size=32)\n",
        "label_map = (generator.class_indices)\n",
        "print(label_map)\n",
        "#y_classes = preds.argmax(axis=-1)\n",
        "#print(y_classes)\n",
        "y_classes = preds1.argmax(axis=-1)\n",
        "print(y_classes)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19 images belonging to 2 classes.\n",
            "{'dhoni': 0, 'virat': 1}\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}