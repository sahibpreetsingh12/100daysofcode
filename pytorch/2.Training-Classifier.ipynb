{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                  TRAINING A CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Vision Pytorch has a Package torchvision, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., torchvision.datasets and torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in Image Classification:-\n",
    "## 1.Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "## 2.Define a Convolutional Neural Network\n",
    "## 3.Define a loss function\n",
    "## 4.Train the network on the training data\n",
    "## 5.Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading And Normalising Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=ts.Compose(\n",
    "    [ts.ToTensor(),\n",
    "    ts.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a PIL Image or numpy.ndarray to tensor.\n",
    "\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
    "\n",
    "# Since its an image, we are sending 3 values of mean and 3 values of std, for each color channels of RGB.\n",
    "\n",
    "# Normalize a tensor image with mean and standard deviation. \n",
    "Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e. \n",
    "# input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset=torchvision.datasets.CIFAR10(root='./data',train=True,\n",
    "                                     download=True,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS USED ABOVE\n",
    "\n",
    "## 1. root parameter is used to tell where we wnat to store the downloaded Dataset \n",
    "\n",
    "## 2. train if this  is set to True then in return we will get Training Datset and otherwise Testing dataset\n",
    "\n",
    "## 3. download is used to tell wthether we want to download dataset or not. Default is False\n",
    "\n",
    "## 4. transform is used to Normalization And Augmentaion of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Some Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "\n",
      "\n",
      "torch.Size([4, 3, 32, 32]) tensor([8, 5, 8, 7])\n",
      " ship   dog  ship horse\n",
      "plane\n",
      "car\n",
      "bird\n",
      "cat\n",
      "deer\n",
      "dog\n",
      "frog\n",
      "horse\n",
      "ship\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(classes[i])#various classes available in CIFAR10 Dataset\n",
    "\n",
    "\n",
    "    \n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "print(type(trainloader))\n",
    "\n",
    "# Iterate over Batch Created Using DataLoader class above and Stored in trailoader\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "#To go to Next labelled Image in Batch\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# in Output for Labels we get tensor([8,5,8,7]) for images of ship,dog,ship,horse \n",
    "#It means ship is present at 9th Position in Our Labels List Printed Above and Dog at 6th,Horse at 8th\n",
    "print(images.shape,labels)\n",
    "\n",
    "\n",
    "# show images in Grid\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "for i in range(10):\n",
    "    print(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why we used np.transpose(npimg,(1,2,0)) ?\n",
    "Because in when we load a Image in Pytorch by Default we Get Image Tensor of(C,H,W) Channels,Height,Width and to plot a Image using Matplolib.pyplot,imshow() we need Image in (H,W,C) format so we transpose the axis to (1,2,0) it means at First Will Come \n",
    "0th axis(i.e Height(1st) by Default in Pytorch) then 1st Axis (i.e Width(2nd) by Default in Pytorch) and Finally\n",
    "2nd axis (i.e Channels(0th axis) By Defualt in Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding a 3rd array In Numpy\n",
    "\n",
    "https://stackoverflow.com/questions/22981845/3-dimensional-array-in-numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define a Convolutional Neural Network\n",
    " \n",
    "A Neural Networks That Takes 3 Chanels(R,G,B) as Input and Output 6 Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 6,kernel_size= (5,5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels= 16, kernel_size=(5,5))\n",
    "        self.fc1 = nn.Linear(in_features= 16 * 5 * 5, out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features=120,out_features= 84)\n",
    "        self.fc3 = nn.Linear(in_features=84,out_features= 10)#10 out_features because in CIFAR 10 has 10 Classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.271\n",
      "[1,  4000] loss: 1.955\n",
      "[1,  6000] loss: 1.721\n",
      "[1,  8000] loss: 1.599\n",
      "[1, 10000] loss: 1.520\n",
      "[1, 12000] loss: 1.483\n",
      "[2,  2000] loss: 1.385\n",
      "[2,  4000] loss: 1.365\n",
      "[2,  6000] loss: 1.336\n",
      "[2,  8000] loss: 1.343\n",
      "[2, 10000] loss: 1.286\n",
      "[2, 12000] loss: 1.301\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the network on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "(3, 36, 138)\n",
      "(36, 138, 3)\n",
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4672, -2.5935,  1.4267,  3.0919,  0.1376,  1.9819,  2.3032, -1.4673,\n",
      "         -1.9415, -2.2187],\n",
      "        [ 3.3593,  7.5976, -2.4274, -3.0181, -3.1492, -3.8883, -3.0764, -3.2031,\n",
      "          4.5116,  5.5202],\n",
      "        [ 0.7406,  2.8366, -0.6208, -0.4732, -1.0569, -1.3020, -0.8451, -1.7205,\n",
      "          1.4786,  2.1155],\n",
      "        [ 3.0836, -0.7787,  1.5598, -0.7594,  1.4738, -2.2851, -1.1669, -1.2778,\n",
      "          1.1623, -0.7696]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat   car   car plane\n"
     ]
    }
   ],
   "source": [
    "#The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class.\n",
    "#So, let’s get the index of the highest energy:\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "#For Complete Dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 62 %\n",
      "Accuracy of   car : 79 %\n",
      "Accuracy of  bird : 43 %\n",
      "Accuracy of   cat : 37 %\n",
      "Accuracy of  deer : 31 %\n",
      "Accuracy of   dog : 43 %\n",
      "Accuracy of  frog : 80 %\n",
      "Accuracy of horse : 54 %\n",
      "Accuracy of  ship : 57 %\n",
      "Accuracy of truck : 60 %\n"
     ]
    }
   ],
   "source": [
    "# See what are the classes that performed well, and the classes that did not perform well:\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
